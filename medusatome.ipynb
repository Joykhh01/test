{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1a6093a7",
   "metadata": {},
   "source": [
    "run on bash\n",
    "sudo apt update\n",
    "sudo apt install tor firefox-geckodriver firefox python3-pandas python3-bs4 python3-selenium\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2919afa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "from datetime import datetime\n",
    "from bs4 import BeautifulSoup\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.firefox.firefox_profile import FirefoxProfile\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2facc68c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start Tor\n",
    "torexe = os.popen('tor')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3122a2af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Firefox Binary and GeckoDriver Paths for Ubuntu\n",
    "firefoxBinary = \"/usr/bin/firefox\"\n",
    "geckodriverPath = \"/usr/bin/geckodriver\"\n",
    "proxyIP = \"127.0.0.1\"\n",
    "proxyPort = 9150\n",
    "\n",
    "# Configure Firefox profile for Tor\n",
    "profile = FirefoxProfile(\"/path/to/your/tor/profile\")  # Replace with the correct path to your Tor profile on Ubuntu\n",
    "\n",
    "profile.set_preference('extensions.torlauncher.start_tor', True)\n",
    "profile.set_preference('network.proxy.type', 1)\n",
    "profile.set_preference('network.proxy.socks', proxyIP)\n",
    "profile.set_preference('network.proxy.socks_port', proxyPort)\n",
    "profile.set_preference(\"network.proxy.socks_remote_dns\", True)\n",
    "profile.update_preferences()\n",
    "\n",
    "# Launch Firefox with GeckoDriver and the configured profile\n",
    "driver = webdriver.Firefox(executable_path=geckodriverPath,\n",
    "                           firefox_binary=firefoxBinary, \n",
    "                           firefox_profile=profile)\n",
    "\n",
    "# Wait until Tor connects to the network\n",
    "driver.get('http://medusaxko7jxtrojdkxo66j7ck4q5tgktf7uqsqyfry4ebnxlcbkccyd.onion/')\n",
    "SCROLL_PAUSE_TIME = 5\n",
    "\n",
    "# Get scroll height\n",
    "last_height = driver.execute_script(\"return document.body.scrollHeight\")\n",
    "\n",
    "while True:\n",
    "    driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "    time.sleep(SCROLL_PAUSE_TIME)\n",
    "    new_height = driver.execute_script(\"return document.body.scrollHeight\")\n",
    "    if new_height == last_height:\n",
    "        break\n",
    "    last_height = new_height\n",
    "\n",
    "companyNames = []\n",
    "companyDescription = []\n",
    "dateVictimised = []\n",
    "noClicks = []\n",
    "\n",
    "cards = driver.find_elements_by_xpath(\"//div[@class='card']\")\n",
    "\n",
    "for card in cards:\n",
    "    dateVictimisedElement = card.find_element_by_xpath(\".//div[@class='date-updated']/span[@class='text-muted']\")\n",
    "    dateVictimisedText = dateVictimisedElement.text\n",
    "    dateVictimised.append(dateVictimisedText)\n",
    "\n",
    "    companyNameElement = card.find_element_by_xpath(\".//h3[@class='card-title']\")\n",
    "    companyNameText = companyNameElement.text\n",
    "    companyNames.append(companyNameText)\n",
    "\n",
    "    companyDescriptionElement = card.find_element_by_xpath(\".//p[@class='card-text text-left']\")\n",
    "    companyDescriptionText = companyDescriptionElement.text\n",
    "    companyDescription.append(companyDescriptionText)\n",
    "\n",
    "    noClicksElement = card.find_element_by_xpath(\".//div[@class='number-view']/span[@class='text-muted']\")\n",
    "    noClicksText = noClicksElement.text\n",
    "    noClicks.append(noClicksText)\n",
    "\n",
    "driver.quit()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79931aa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({\"Company\": companyNames, \"Company Description\": companyDescription, \"Date Victimised\": dateVictimised, \"Number of Clicks\": noClicks})\n",
    "df['Date Victimised'] = pd.to_datetime(df['Date Victimised'], format='%Y-%m-%d %H:%M:%S')\n",
    "\n",
    "date_mask = df['Date Victimised'].dt.year < 2024\n",
    "df = df[~date_mask]\n",
    "df.reset_index(drop=True)\n",
    "df.to_csv(\"Medusa_Data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c70150f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use WebDriver Manager for Chrome (Ubuntu)\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "import requests\n",
    "\n",
    "driver = webdriver.Chrome(ChromeDriverManager().install())\n",
    "driver.maximize_window()\n",
    "\n",
    "def location_to_country(location):\n",
    "    base_url = \"https://nominatim.openstreetmap.org/search\"\n",
    "    params = {\n",
    "        \"addressdetails\": 1,\n",
    "        \"q\": location,\n",
    "        \"format\": \"jsonv2\",\n",
    "        \"limit\": 1\n",
    "    }\n",
    "    response = requests.get(base_url, params=params)\n",
    "    data = response.json()\n",
    "    if data:\n",
    "        return data[0].get(\"address\", {}).get(\"country\", \"\")\n",
    "    return np.nan\n",
    "\n",
    "companyWebsite_list = []\n",
    "industry_list = []\n",
    "headquarter_list = []\n",
    "country_list = []\n",
    "\n",
    "wait = WebDriverWait(driver, 5)\n",
    "\n",
    "for company in companyNames:\n",
    "    try:\n",
    "        driver.get('https://www.google.com')\n",
    "        search = driver.find_element(By.NAME, 'q')\n",
    "        search.send_keys(company + ' linkedin')\n",
    "        search.send_keys(Keys.RETURN)\n",
    "        linkedin_page = driver.find_element(By.TAG_NAME, 'h3')  # clicking the first search result\n",
    "        time.sleep(2)\n",
    "        linkedin_page.click()\n",
    "\n",
    "        if \"linkedin\" in driver.current_url:\n",
    "            loaded = wait.until(EC.presence_of_element_located((By.ID, \"main-content\")))\n",
    "\n",
    "            try:\n",
    "                website_element = driver.find_element(By.CSS_SELECTOR, '[data-test-id=\"about-us__website\"]')\n",
    "                website_text_element = website_element.find_element_by_xpath(\".//dd[@class='font-sans text-md text-color-text break-words overflow-hidden']\")\n",
    "                website_text = website_text_element.text\n",
    "            except Exception:\n",
    "                website_text = np.nan\n",
    "            companyWebsite_list.append(website_text)\n",
    "\n",
    "            try:\n",
    "                industry_element = driver.find_element(By.CSS_SELECTOR, '[data-test-id=\"about-us__industry\"]')\n",
    "                industry_text_element = industry_element.find_element_by_xpath(\".//dd[@class='font-sans text-md text-color-text break-words overflow-hidden']\")\n",
    "                industry_text = industry_text_element.text\n",
    "            except Exception:\n",
    "                industry_text = np.nan\n",
    "            industry_list.append(industry_text)\n",
    "\n",
    "            try:\n",
    "                headquarters_element = driver.find_element(By.CSS_SELECTOR, '[data-test-id=\"about-us__headquarters\"]')\n",
    "                headquarters_text_element = headquarters_element.find_element_by_xpath(\".//dd[@class='font-sans text-md text-color-text break-words overflow-hidden']\")\n",
    "                headquarters_text = headquarters_text_element.text\n",
    "                country = location_to_country(headquarters_text)\n",
    "            except Exception:\n",
    "                headquarters_text = np.nan\n",
    "                country = np.nan\n",
    "            headquarter_list.append(headquarters_text)\n",
    "            country_list.append(country)\n",
    "        else:\n",
    "            companyWebsite_list.append(np.nan)\n",
    "            industry_list.append(np.nan)\n",
    "            headquarter_list.append(np.nan)\n",
    "            country_list.append(np.nan)\n",
    "\n",
    "    except Exception:\n",
    "        companyWebsite_list.append(np.nan)\n",
    "        industry_list.append(np.nan)\n",
    "        headquarter_list.append(np.nan)\n",
    "        country_list.append(np.nan)\n",
    "\n",
    "driver.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52d86eb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"Company Website\"] = companyWebsite_list\n",
    "df[\"Industry\"] = industry_list\n",
    "df[\"Location\"] = headquarter_list\n",
    "df[\"Country\"] = country_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f5895d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"Medusa_Linkedin_Data.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
